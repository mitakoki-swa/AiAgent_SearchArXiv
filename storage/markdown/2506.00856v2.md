Title: Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks

URL Source: http://arxiv.org/pdf/2506.00856v2

Published Time: Mon, 16 Jun 2025 00:57:49 GMT

Markdown Content:
> arXiv:2506.00856v2 [econ.EM] 13 Jun 2025

# Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks 

Qiang Chen ∗a, Tianyang Han †b, Jin Li ‡b, Ye Luo §b, Yuxiao Wu ¶b, Xiaowei Zhang ‖c,and Tuo Zhou ∗∗ baSchool of Economics, Shandong University 

> b

HKU Business School, The University of Hong Kong 

> c

School of Engineering, Hong Kong University of Science and Technology 

ABSTRACT 

Can AI effectively perform complex econometric analysis traditionally requiring human expertise? This paper evaluates AI agents’ capability to master econometrics, focusing on empirical analysis performance. We develop an “Econometrics AI Agent” built on the open-source MetaGPT frame-work. This agent exhibits outstanding performance in: (1) planning econometric tasks strategically, (2) generating and executing code, (3) employing error-based reflection for improved robustness, and (4) allowing iterative refinement through multi-round conversations. We construct two datasets from academic coursework materials and published research papers to evaluate performance against real-world challenges. Comparative testing shows our domain-specialized AI agent significantly out-performs both benchmark large language models (LLMs) and general-purpose AI agents. This work establishes a testbed for exploring AI’s impact on social science research and enables cost-effective integration of domain expertise, making advanced econometric methods accessible to users with minimal coding skills. Furthermore, our AI agent enhances research reproducibility and offers promising pedagogical applications for econometrics teaching. 

Keywords : Econometrics, Empirical Replication, AI Adoption, Agentic AI 

JEL classification: A20, B41, C49, C87 

> ∗email: qiang2chen2@126.com
> †email: tyhan@connect.hku.hk
> ‡email: jli1@hku.hk
> §email: kurtluo@hku.hk
> ¶email: wyx2000@connect.hku.hk
> ‖email: xiaoweiz@ust.hk
> ∗∗ email: zhoutuo@connect.hku.hk

# I. Introduction 

As AI becomes a major topic in mainstream media since ChatGPT’s launch (OpenAI, 2023), public expectations have soared regarding generative AI’s potential to enhance productivity and efficiency. This excitement has quickly spread throughout academia, particularly in economics, business, and social sciences. Recent studies demonstrate promising applications: Li et al. (2024) showed that Large Language Models (LLMs) could effectively substitute for human participants in marketing research, particularly in perceptual analysis, while Chakraborty et al. (2025) proved the effectiveness of AI and AI-human hybrid models in salesforce hiring, achieving high prediction accuracy through conversational video interviews with minimal professional involvement. However, despite these advances, LLMs face significant limitations in practical applications. Current studies primarily restrict LLMs to generating brief textual content or utilizing basic ca-pabilities within general knowledge domains (Korinek, 2023). More challenging tasks reveal fun-damental constraints: LLMs struggle with complex analytical tasks (Xu et al., 2024) and require costly specialized training for knowledge-dense domains (Ling et al., 2024). As AI’s underlying models rapidly evolve, a new paradigm called AI Agent has emerged (https://aws.amazon.com/what-is/ai-agents/). An AI agent is a software program that can in-teract with its environment, collect data, and independently perform self-determined tasks to meet predetermined goals. This evolution represents a significant advancement beyond traditional LLMs, as AI agents promise to handle complex, professional-level tasks with greater autonomy. The practical applications are already evident, such as Amazon’s Alexa+ which manages house-hold appliances through personalized conversational interfaces. The development of numerous high-profile open-source frameworks further validates this trend. For instance, Microsoft’s Au-toGen (https://github.com/microsoft/autogen) provides a comprehensive framework for creating multi-agent AI applications that can act autonomously or work alongside humans. Both academia and industry acknowledge AI agents’ promising future, as reflected in notable statements: “I expect that the set of tasks AI could do will expand dramatically this year because of agentic workflows.” — Andrew Ng (Stanford University) at AI Ascent 2024 Conference. “Nvidia will one day have 50,000 employees and over 100 million AI assistants” — Jensen Huang (NVidia) at Gartner IT Symposium/Xpo 2024. While AI agent applications are rapidly advancing in industry, their adoption in academic research remains limited. Our paper addresses this gap by developing AI agent applications specif-ically for business, economics, and social sciences research. We design and implement a zero-shot learning framework 1, called Econometrics AI Agent , that enables generalist AI agents to acquire domain knowledge without costly LLM fine-tuning. The 

> 1Zero-shot learning is a machine learning concept first raised in Lampert et al. (2009). Under the zero-shot learning setup, a learner is expected to observe entities from the classes not covered in the training samples and make correct inferences and predictions. For the LLM setting, zero-shot learning denotes the content generation process towards tasks never learned by LLMs, without fine-tuning LLMs or prompting LLMs with specific samples.

2framework’s core component is an econometrics “tool library” implementing popular econometric methods, including IV-2SLS (instrumental variable regression with two-stage least squares), DID (difference-in-difference), and RDD (regression discontinuity design). These methods typically chal-lenge leading benchmark LLMs like OpenAI GPT-4o, which struggle to understand and implement them correctly (for detailed evidence, see Section V). To bridge this capability gap, we augment each econometric tool with detailed “prompts”— comprehensive method descriptions that specify inputs, hyperparameters, and outputs. These prompts are provided alongside corresponding Python implementations, creating a standardized interface between the econometric methods and the AI agent. This design allows the LLM to leverage both its general econometric knowledge and the specifically crafted prompts and tools, enabling it to conduct complex econometric analyses through multi-round interactions with users. The resulting framework empowers Econometrics AI Agent to independently handle applied econometric tasks, delivering comprehensive results that include parameter estimation, inference, and analytical discussions. Compared to prevalent approaches like model fine-tuning or pure prompt engineering, our design offers a more efficient solution for domain knowledge-intensive problems, achieving high accuracy at lower cost. To validate Econometrics AI Agent’s professionalism, efficiency, and autonomy, we conduct comprehensive empirical tests using real-world applications. Our test dataset comprises applied econometrics tasks from published academic papers and Ph.D.-level coursework assignments. We standardize these econometric questions into structured prompts that can be processed by both Econometrics AI Agent and benchmark LLMs. We evaluate Econometrics AI Agent’s performance against three control groups: (i) direct LLM generation in Python code, (ii) direct LLM generation in Stata code, and (iii) baseline general-purpose AI agents without specialized econometric tools and domain knowledge. The experimental results demonstrate Econometrics AI Agent’s superior performance. While LLMs’ direct code generation successfully completes less than 50% of complex tasks, our domain-knowledge-enhanced AI agent achieves nearly perfect completion rates. Furthermore, Econometrics AI Agent achieves significantly higher replication accuracy, with rates above 66% for course assign-ments (relatively easier tasks) and above 40% for published paper tasks (more complex tasks). In contrast, control groups achieve only 33% and 30% replication rates for easier and complex tasks, respectively. The Econometrics AI Agent framework offers significant implications for the global adoption of AI technology. Our structural design provides a cost-effective approach to integrating domain expertise, transforming AI agents into genuine productivity enhancers. In empirical research across business, economics, and social sciences, this framework reduces educational barriers by enabling students and practitioners to utilize sophisticated econometric tools without extensive specialized training. Beyond econometrics, our design’s modular architecture allows for seamless integration of domain knowledge into AI agent “knowledge libraries” across various fields. This extensibil-ity makes our framework a valuable template for developing domain-specific AI agents in other 3disciplines. Our work contributes to business, economics, and social sciences research in three crucial ways. First, the Econometrics AI Agent’s robust capabilities in applied econometrics can significantly accelerate both adoption of new econometric methods and empirical research processes. Second, it enhances research reproducibility by providing standardized implementation of econometric meth-ods. Third, it provides researchers a concrete case study to investigate AI’s impact not merely as a content generation tool, but as an autonomous productivity enhancer. This shift in perspec-tive enables more nuanced investigations into AI’s broader implications for economic and societal development. The remainder of this paper is organized as follows. Section II reviews the emerging literature on LLM applications, highlighting our contributions. Section III introduces the Econometrics AI Agent’s design, focusing on its domain knowledge integration and applied econometrics capabilities. Section IV details our evaluation methodology, including dataset construction from coursework assignments and published papers, assessment criteria, and performance comparisons with other LLM-based tools. Section V presents two in-depth case studies demonstrating the Econometrics AI Agent’s task-solving procedure and its advantages over existing LLM-based solutions. Section VI discusses potential applications and concludes. The Econometrics AI Agent package is available at https://github.com/HKU-Business-AI-Center/Econometrics-Agent. 

# II. Literature Review 

Our paper relates to the growing literature on LLM applications in business, economics, and so-cial sciences, where LLMs primarily serve as tools for analyzing unstructured textual data, replacing traditional natural language processing techniques. Research has demonstrated LLMs’ fundamen-tal content creation capabilities in various settings. Stroube and Waguespack (2024) used GPT-4 to generate synthetic gender-neutral movie pitches to control for gender influence in quality evalu-ation. Yoganarasimhan and Iakovetskaia (2024) applied GPT-3.5 Turbo to calculate polarization scores for articles and topics in social media analysis. Abraham et al. (2024) utilized ChatGPT to generate ESG scores from PE firms’ websites, improving upon dictionary-based measurements. Armstrong et al. (2024) applied the GPT-3.5 Turbo to quantify the firm exposure in Securities Exchange Commission agencies but received insignificant enhancement. Niu et al. (2025) verified the consistency of “bag-of-words” technique by GPT-4 when measuring the effect of manufactur-ers’ service offerings on demand variability. Noailly et al. (2024) utilized EnvP-BERT fine-tuned with environmental policies to capture climate-related indexes, which obtained resembling accu-racy. Apart from generating numeric data by analyzing the implication of the context, LLMs are additionally exerted in detecting the similarity by tokenizing context as vectors and afterward cal-culating the distances in different norms (Bursztyn et al., 2022; Graeber et al., 2024; Ahrens et al., 2025; Gorodnichenko et al., 2025; Curti and Kazinnik, 2023; Balsmeier et al., 2024). Most existing research focuses on direct applications of LLMs’ language capabilities, primarily 4using simple prompts to extract information from textual data. Due to LLMs’ limited capabilities in specific domains like econometrics, their application in these areas remains restricted. Our paper advances this literature by endowing LLMs with domain knowledge through the Econometrics AI Agent framework. This enables social science researchers to efficiently implement advanced econometric methodologies, expanding LLMs’ utility beyond basic content generation. Specifically, there have been recent studies discussing potential revolutionary roles of LLMs in econometrics. From a theoretical perspective, Manning et al. (2024) investigated LLMs’ capability in social science research through automated structural causal model development and in silico simulations. Ludwig et al. (2025) derived conditions under which LLMs can effectively conduct economic measurement prediction and estimation tasks. From an empirical perspective, Han (2025) developed a multi-step prompt engineering method to validate LLMs’ capability in identifying valid IVs for causal discovery. Our paper contributes directly to LLMs’ empirical application in econometrics, focusing on automating researchers’ complete hands-on workflow. Moreover, thanks to its extensible workflow and tool package design, our Econometrics AI Agent framework supports smooth integration of fast-evolving AI-driven econometrics methodologies from academia, while serving as a platform for deploying these research outcomes in real-world applications. Our second contribution relates to the literature exploring AI’s economic impact and human-AI interaction. Previous research has extensively studied productivity effects. Hui et al. (2024) found that ChatGPT usage among freelancers reduces skill-based gaps in highly affected occupations, impacting both earnings and employment. Brynjolfsson et al. (2025) demonstrated heterogeneous productivity gains among customer service workers using LLM-based conversational guidance sys-tems. Similar productivity effects were found by Noy and Zhang (2023) in professional writing and Dell’Acqua et al. (2023) in consulting, where AI augmentation improved performance within AI-capable tasks but showed limitations beyond the AI’s capability frontier. These productivity shifts have broader implications, as Meltzer (2024) discussed in analyzing po-tential job market changes across manufacturing and international trade, emphasizing the need for regulatory frameworks. Beyond productivity, Generative AI influences other economic behaviors. Leib et al. (2023) found that AI-generated dishonesty-promoting suggestions affect human honesty similarly to human advice, while Doshi and Hauser (2024) revealed that LLMs enhance individual creative writing but may reduce global novelty by channeling creativity in similar directions. Research has also examined LLMs’ decision-making patterns compared to humans. Goli and Singh (2024) found LLMs prefer lower discount rates and earlier rewards in intertemporal choices, with effects moderated by language features. Chen et al. (2025) identified varying risk and cer-tainty preferences across different LLM models in operations management decisions. Regarding oc-cupational assessment, Gmyrek et al. (2024) found GPT-4 generally aligns with human judgments, except for overestimating digital economy roles and underestimating non-conventional occupations. While these studies explore LLMs’ economic impact across various dimensions, their research designs focus on LLMs’ current capabilities and limitations. None examines the impact of domain-specific AI agents, which represent a more advanced application of LLMs with enhanced robust-5ness and task-solving capabilities. Our paper addresses this gap. Through our agent design, we demonstrate how LLMs can transcend basic content generation to become effective task solvers and productivity enhancers. By studying how professionally-equipped AI agents impact practical users, we expand the scope of social science research into advanced AI applications. Lastly, our paper makes a technical contribution, addressing the challenge of enhancing LLMs’ domain knowledge performance through a cost-effective solution. Current approaches primarily rely on expensive and time-consuming methods. These include fine-tuning models with curated domain-specific data, such as BloombergGPT (Wu et al., 2023) for finance and Med-PaLM 2 (Singhal et al., 2025) for medicine, or using lightweight fine-tuned LLMs to guide other LLMs (Yao et al., 2023). Alternative approaches focus on complex prompt engineering to generate domain knowledge content (Liu et al., 2025). However, without proper workflow and self-reflection mechanisms, these direct LLM applications remain vulnerable to hallucination issues that can significantly impact output quality. The Econometrics AI Agent’s structural design implements a zero-shot learning framework that ensures high task-solving performance at minimal cost. Our approach minimizes hallucinations through two key mechanisms. First, domain knowledge toolkit integration prevents hallucinations in code generation and execution, limiting potential errors to tool selection and calling procedures. Second, self-reflection processes further reduce hallucinations by validating execution outputs and implementing error corrections. This design framework can be extended to other domains, particu-larly those with limited textual training samples or frequent knowledge updates, enabling efficient development of customized AI agents with domain-specific tools. 

# III. Methodology 

Current LLM tools face two primary limitations: they struggle to deliver complete workflows and perform poorly in knowledge-dense domains. The Econometrics AI Agent addresses both challenges through a customized AI Agent system and a zero-shot learning framework, enabling accurate and executable workflows without the substantial costs of LLM retraining. 

A. Overview of Econometrics AI Agent Structure 

LLM-based AI agents are autonomous systems that perceive instructions, reason about com-plex tasks, and execute actions to achieve specified goals through code execution and tool usage. While generic LLM agents can handle open-ended queries, they struggle in expert domains such as econometrics, where problem-solving requires adherence to established analytical steps and spe-cialized methods. Recent AI agent frameworks demonstrate that incorporating structured domain knowledge significantly enhances performance. MetaGPT (Hong et al., 2024a) encodes procedural knowledge as Standardized Operating Procedures within prompt sequences, using specialized sub-agents to verify intermediate results and decompose complex tasks. The Data Interpreter agent (Hong et al., 2024b) uses a hierarchical task graph and iterative refinement modules for end-to-end 6data-science workflows. Building on these advances, the Econometrics AI Agent features a customized architecture specifically designed to embed econometric domain expertise into its core operations. This spe-cialization moves beyond the capabilities of general-purpose agents or direct LLM interactions by incorporating specific structural enhancements tailored for econometric analysis. A cornerstone of this specialized structure lies in enhanced task decomposition. When pre-sented with an econometric problem ( User Input in Figure 1), the agent’s Plan Generation module follows predefined templates reflecting standard econometric research paths—such as causal infer-ence strategies and time-series analysis workflows—rather than relying solely on generic planning. This approach decomposes complex requests into logically sequenced, econometrically meaningful sub-tasks. These sub-tasks are categorized using specific econometric actions like “instrumental variable selection” and “difference-in-differences pre-trend check,” enabling more precise execution than generic labels. 

Figure 1. Workflow of Econometrics AI Agent 

Crucially, executing these specialized sub-tasks requires more than the LLM’s reasoning capa-7bilities. Thus, another key structural enhancement is the integration of a unique Econometrics Tool Library. During the Tool Selection and Program Execution phases (Figure1), the agent accesses a bespoke set of Python functions implementing various econometric methods (e.g., OLS, PanelOLS, IV-2SLS, DID, RDD, propensity score methods), including options for robust standard errors and fixed effects. As detailed in Section III.B, these tools are described with internal prompts that enable the LLM core to understand their functionality and application context. This structured approach, where the agent selects and invokes validated tools, minimizes LLM hallucination risk for complex algorithms and ensures adherence to econometric practices—a distinct advantage over general agents lacking such domain-specific implements. Furthermore, recognizing empirical analysis as an iterative process, the Econometrics AI Agent incorporates sophisticated multi-round conversational capabilities with intent recognition and mem-ory. When users provide subsequent instructions ( multi dialogue loop in Figure 1), an Intent Recog-nition mechanism assesses whether the new input relates to the ongoing analysis or initiates a new task. For continuing analyses, the agent retrieves context from its Memory—including current data state, generated code, existing plan, and environment variables within its sandboxed execution en-vironment. It then updates the Plan Generation phase, modifying or adding sub-tasks as needed, and resumes execution from the appropriate point. For new tasks, it initializes a fresh environ-ment. This mechanism enables users to iteratively refine analyses, correct misunderstandings, or explore alternative specifications conversationally, ensuring outputs align with evolving research requirements. These core structural enhancements—particularly the domain-tailored task decomposition and the unique econometrics toolkit—work in concert to ensure the Econometrics AI Agent’s effective-ness. The agent’s step-by-step reasoning is grounded in econometric best practices, while code execution relies on robust, pre-defined functions, leading to more reliable and accurate outcomes. This built-in domain expertise substantially reduces logical errors and methodological misapplica-tions compared to general agents. A key advantage of this design is its extensibility through a zero-shot prompting framework with tool use, allowing the agent to incorporate new econometric methods without LLM retraining. Unlike the costly and often infeasible process of fine-tuning an LLM to keep pace with rapid academic advances in developing new techniques, our agent can be updated simply by adding new tool functions and descriptions to the prompt library. This modularity allows the agent’s knowledge base to expand alongside the field’s developments, making the integration of recently published procedures as straightforward as adding new modules. Such capability ensures the agent’s state-of-the-art performance while potentially enabling the transfer of this structured approach to other specialized domains. In short, by combining LLM-driven reasoning with domain-specific planning structures and a dedicated toolkit, the Econometrics AI Agent achieves performance, robustness, accuracy, and adaptability beyond the capabilities of generic AI agents. The architecture executes complete econometric analyses end-to-end, delivering rigorous results while dynamically incorporating user 8feedback through its interactive workflow. 

B. Customization Towards Econometrics Tasks 

LLMs are generative pre-trained transformers that learn from massive amounts of textual data across various knowledge domains, enabling strong performance in general topics (Wang et al., 2019). However, achieving professional-level capability in specialized domains remains challenging, particularly in econometrics where two major limitations affect LLM fine-tuning. First, econometric methods and algorithms rapidly evolve through academic journals, creating an expanding frontier of new knowledge. LLMs struggle to keep pace with these developments: frequent fine-tuning or retraining incurs prohibitive time and financial costs (Xia et al., 2024), while limited availability of training data—both textual explanations and code—for new methods constrains learning capabilities. Second, novel econometric methodologies often face slow adoption and knowledge diffusion among empirical researchers and practitioners, resulting in insufficient training samples for LLM learning and performance. The Econometrics AI Agent framework achieves proper understanding and accurate appli-cation of econometric knowledge through a zero-shot learning approach. This is accomplished via an econometrics algorithm tool package designed specifically for LLM use rather than hu-man users. Unlike traditional packages familiar to econometricians in Stata and R, our Python-scripted package incorporates system prompts engineered for LLM comprehension. The cur-rent tool package supports popular empirical econometric applications including general linear models, propensity score methods, IV-2SLS regression, static/staggered difference-in-differences, and sharp/fuzzy RDD. All econometric models and methodologies use function calling format (https://platform.openai.com/docs/guides/function-calling), supporting flexible natural language inputs for econometric tasks. More importantly, each function in the tool library includes a carefully designed internal prompt that introduces the background knowledge of the relevant econometric method and provides im-plementation guidance. These prompts define and explain hyper-parameters that enable flexible tool usage based on user requirements—for example, choosing between regular and robust standard errors in OLS. These system prompts enhance the LLM’s understanding of different econometric tools’ functionality, allowing accurate tool selection through reasoning when addressing user tasks. An example of tool functions and internal prompts is provided in Figure A.1 in Appendix A. These tool packages are written in Python format to match the Econometrics AI Agent’s code execution environment. As previously introduced, an LLM serves as the agent’s core, understanding available tools, selecting appropriate ones for given tasks, and carefully extracting inputs from user commands, including datasets, econometric methodologies, and related hyper-parameters. Each tool features carefully designed functional arguments that meet researchers’ needs while maintaining sufficient flexibility to handle diverse, customized econometric tasks. The tool packages’ functionality builds upon established Python packages for simpler econo-metric algorithms (like OLS and logistic regression), while complex algorithms lacking available 9packages (such as staggered DID event study and fuzzy RDD) are developed on our own following standard Python package formats. Each tool package includes a detailed description prompt— effectively a “manual for LLMs”—that instructs the core LLM about the package’s use. This design implements zero-shot learning (Lampert et al., 2014; Larochelle et al., 2008), allowing the LLM to learn directly from its environment and access relevant knowledge without training or fine-tuning costs. An example of the complete tool-selection-and-implementation workflow is provided in Fig-ure A.2 in Appendix A. During initialization, the LLM processes each registered tool’s internal prompt, summarizing four key aspects: target scenario, input requirements, output structure, and special requirements (if any). The Econometrics AI Agent ranks available tools based on their target scenarios, selecting the highest-scoring tool for the current task. The LLM then generates code to ensure inputs meet tool package requirements while outputs fulfill user needs. One might question whether LLM code generation capabilities could replace tools specifically designed for LLM use, suggesting that direct code generation might suffice given that Python and Stata package documentation is publicly available and likely included in LLM training data. However, limited training samples for specific econometric methods prevent LLMs from master-ing domain knowledge and ensuring reliable performance. The test results in Sections IV and V demonstrate the critical importance of our tool package zero-shot learning framework. Our design has several key advantages. First, it requires no econometrics-specific LLM tuning. General-domain LLMs (such as GPT-4o and LLaMA 3) perform effectively within the Econometrics AI Agent framework, as demonstrated in our empirical tests using unmodified GPT-4o. Second, since all tool methods are fixed functions—although accepting flexible inputs—hallucination within econometric algorithms is eliminated. The LLM’s role is limited to understanding tool application scenarios and selecting/calling appropriate tools, with any remaining errors readily caught by the code compiler. Last but not least, the zero-shot learning framework enables simple integration of new algorithms and methodologies in Python function format, allowing continuous expansion of the econometric “ecosystem” and enhancement of the Econometrics AI Agent’s capabilities. 

# IV. Empirical Tests 

A. Data Source and Summary Statistics 

We evaluate the Econometrics AI Agent through two sets of inquiries. The first comprises 18 exercises from the coursework assignments of a doctoral-level course titled “Applied Economet-rics” at the University of Hong Kong, with Python-generated standard solutions. These exercises cover OLS & PanelOLS regression, propensity score matching, IV-2SLS regression, Difference-in-Differences (DID) analysis, and Regression Discontinuity Design. The second set consists of test datasets from randomly selected seminal articles in reputable journals, primarily accompanied by Stata-based replication packages. Table I and Figure 2 show the distribution of econometric algorithms across both test datasets. 10 Assignments Published Papers Number of Samples (Percentage)                   

> OLS & Panel OLS 8 (44.4%) 23 (51.1%) Propensity Score 2 (11.1%) 6 (13.3%) Instrument Variable (IV) 2 (11.1%) 8 (17.8%) Difference-in-Differences (DID) 2 (11.1%) 3 (6.7%) Regression Discontinuity Design (RDD) 4 (22.2%) 5 (11.1%) Data Processing 13 (72.2%) 23 (51.1%) Covariance Adjustment 14 (77.8%) 29 (64.4%) Fixed Effects 4 (22.2%) 24 (53.3%) Total 18 45

Table I . Testset Summary Statistics OLS and PanelOLS emerge as the predominant methodologies in empirical research in business, economics, and social sciences, while advanced causal analysis techniques like IV and DID also make significant contributions. The Econometrics AI Agent supports these algorithms, enabling automated research workflows with minimal development time and cost. All test datasets are available in the study’s online appendix. 

Figure 2. Task Distribution (Econometric Methods) 

B. Test Design 

Our empirical test adopts a structural prompt template to construct detailed questions. To demonstrate the Econometrics AI Agent’s capabilities, we present results against control groups using standardized evaluation metrics. 11 B.1. Prompt Structure 

While LLMs can process prompts of varying lengths, tones, attitudes, languages, and formats, their performance may be affected by potential latent factors in these prompts (He et al., 2024). To ensure consistent performance evaluation, we standardized the prompt format across all test ques-tions. Each prompt must specify the data source, proposed econometric methodology, treatment variable, dependent variable, control variables, and customized requirements (such as data pro-cessing, fixed effects, robust standard errors, or methodology-specific settings). These components are integrated into a fixed prompt structure. For illustration, consider this example from Anderson (2008) using staggered DID event study to estimate safety belt legislation effects on traffic fatalities: 

Please use the Staggered DID Event Study method to compute the effect of “pri-mary” on “log f atality rate ”. There is no control variable .Besides, you need to consider the following requirements: divide states into two groups by the median value of population in 1982 and choose the high-population group. For the event study setting, set the see-back length as 4 and see-forward length as 3. Need to construct log f atality rate as the dependent variable, by taking the direct logarithm of f atality rate . Add state fixed effect, year fixed effect and cluster standard error by state. Out-put the result of coefficient towards “Lag D 1” term. 

You could load the corresponding data from /home/data/DID sample data.dta .At the end of the program, please print the coefficient, standard error and p-value of the effect in a json format like {“coef f icient ” : 1 , “standard error ” : 2 , “p-value ” : 0 .5},and output the json string as a .json file. 

In this prompt template, boldface elements vary across questions to accommodate different econometric tasks, while the remaining structure stays fixed. For researchers familiar with econo-metric analysis, the workflow typically involves data exploration and cleaning, programming lan-guage selection, code implementation, and debugging. However, those without sufficient economet-ric experience face a more challenging process, often requiring extensive trial-and-error iterations. 

B.2. Test Procedure and Evaluation Metrics 

The generated prompts are fed directly to the Econometrics AI Agent, which automatically executes Python code in a Jupyter kernel and iteratively updates based on error messages. As detailed in Section III, the program terminates upon completion, storing results in JSON format. All scripts and outcomes are preserved for review, allowing users to interact with the AI agent through multi-round conversations for result revision and additional tasks. Performance evaluation compares the generated coefficient, standard error, and p-value against standard solutions from coursework materials or original papers. We assess coefficient direction and 

L1-norm distance (coefficients and standard errors in percentage, p-values in absolute distance). 12 Two replication standards are defined: perfect replication requires all three errors to be below 1%, while partial replication requires coefficient and standard error gaps below 5%. To demonstrate the Econometrics AI Agent’s capabilities, we establish three control groups: 2

1. Direct GPT-4o Python code generation: We test the single-round code generation ability of GPT-4o by feeding it our structured prompts prefixed with “use Python language to compute the following task” and manually executing the generated code. This serves as a baseline for comparison. 2. Direct GPT-4o Stata code generation: Similar to the first control, but testing LLM code generation in Stata, the most popular software in empirical research. Results are recorded in “.smcl” log files. 3. General-purpose Data Interpreter agent (Hong et al., 2024b): We test a standard AI agent for data analysis without econometric tool packages. This comparison highlights the advantages of our zero-shot learning framework and specialized tool package. 

C. Test Result Summary 

Table II summarizes the performance of the four groups on the coursework assignment problems. The Econometrics AI Agent demonstrates superior performance with a 95% directional replication rate and average coefficient value errors below 3%. In contrast, both GPT-generated Python and Stata control groups show incorrect directions in over half of test cases. While the general AI Agent achieves a 78% directional replication rate, its coefficient values frequently deviate significantly from true values. In addition, the Econometrics AI Agent perfectly replicates over 60% of cases, compared to ap-proximately 20% for control groups. Its robust econometric toolkit and systematic internal prompts yield higher replication rates for advanced algorithms and complex procedures. Furthermore, both AI agents—Econometrics AI Agent and general-purpose AI agent (Data Interpreter)—achieve per-fect compilation rates through error-feedback mechanisms, while direct LLM generation groups compile successfully less than 50% of the time. Table III presents results from the paper replication dataset. Given Stata’s dominance in empir-ical research across business, economics, and social sciences, the Stata code generation group holds a natural advantage over Python-based approaches. Indeed, GPT-generated Stata code outperforms GPT-generated Python code across most evaluation metrics. Nevertheless, the Econometrics AI Agent achieves superior performance even in this Stata-favorable context, with a 93% directional replication rate—40% higher than the Stata control group. Academic paper tasks present greater complexity than coursework, requiring detailed specifica-tions, customized model structures, and various covariate adjustment methods. Nevertheless, the Econometrics AI Agent consistently outperforms all control groups across key metrics: coefficient 

> 2To ensure clear performance differentiation across all the four groups, we consistently use GPT-4o as the base model for both direct response generation and agent empowerment. For the Stata-based tests, we manually collect metrics from summary tables, bypassing JSON file generation due to Stata’s language constraints.

13 GPT(Py) GPT(Stata) General AI Agent Econometric AI Agent Overall Performance 

Compilation Success 35.56% 23.33% 98.89% 98.15% Perfect Replication 12.22% 10% 28.89% 51.85% Partial Replication 16.67% 11.11% 33.33% 59.26% 

Coefficient 

Correct Direction 35.56% 21.11% 74.44% 92.59% Coefficient Median Error 0.99% 0.04% 5.15% 0.01% Coefficient Error < 1% 17.78% 11.11% 32.22% 62.96% Coefficient Error < 10% 30% 15.56% 43.33% 70.37% 

Standard Error 

Standard Error Median Error 2.14% 2.12% 2.14% 0.34% Standard Error Error < 1% 13.75% 8.75% 28.75% 50% Standard Error Error < 10% 32.5% 17.5% 51.25% 75% 

P-value & Significant Level 

P-value Average abs Error .0197 .0306 .0691 .0357 P-value Median abs Error 0 .0004 0 0P-value abs Error < 1% 37.5% 15% 62.5% 83.33% P-value abs Error < 10% 37.5% 16.25% 66.25% 85.42% Significant Level Correctness 37.5% 17.5% 66.25% 85.42% Significant Level Error == 1 0 0 2.5% 4.17% Significant Level Error == 2 1.25% 0 1.25% 0Significant Level Error == 3 0 1.25% 8.75% 4.17% 

Partial Replication based on Task Type 

OLS, Panel OLS 32.5% 7.5% 47.5% 50% Propensity Score Regression 0 0 0 33.33% Instrument Variable (IV) 20% 60% 80% 100% Differences in Differences (DID) 0 0 30% 33.33% Regression Discontinuity Designs (RDD) 0 5% 0 83.33% Data Processing 16.92% 15.38% 38.46% 69.23% Covariance Adjustment 14.29% 14.29% 32.86% 57.17% Fixed Effects 30% 0 55% 33.33% Number of Tasks 90 90 90 54 

Table II . Assignment Testset Performance estimation error, standard error estimation error, p-value estimation error, and partial replication rates for different econometric algorithms and procedures. These results demonstrate the Agent’s capability to handle complex econometric tasks autonomously while delivering reliable results. Despite substantially outperforming control groups, the Econometrics AI Agent does show room for improvement. For example, its performance declines for complex econometric methods like DID and RDD compared to simpler approaches such as OLS and IV-2SLS. Similarly, results slightly dete-riorate when moving from straightforward coursework problems to more sophisticated paper replica-tion tasks. However, these limitations can be addressed through the AI agent’s domain knowledge architecture—specifically by developing customized tools and enhancing prompt instructions to better support complex algorithms and detailed requirements. 

# V. Case Study 

Following the empirical results presented in Section IV, we demonstrate the Econometrics AI Agent’s problem-solving approach through a comprehensive case study, comparing its procedures 14 GPT(Py) GPT(Stata) General AI Agent Econometric AI Agent Overall Performance 

Compilation Success 28.89% 38.89% 92.59% 93.33% Perfect Replication 8.44% 17.78% 14.81% 27.41% Partial Replication 13.78% 22.22% 35.56% 37.78% 

Coefficient 

Correct Direction 24.44% 36.11% 80.74% 87.41% Coefficient Median Error 0.86% 0.00% 3.24% 0.40% Coefficient Error < 1% 12.44% 18.89% 29.63% 46.67% Coefficient Error < 10% 13.33% 24.44% 48.15% 57.04% 

Standard Error 

Standard Error Median Error 1.84% 0.00% 9.71% 8.82% Standard Error Error < 1% 11.58% 22.37% 16.67% 24.56% Standard Error Error < 10% 20.53% 28.95% 38.60% 43.86% 

P-value & Significant Level 

P-value Average Error .0385 .0160 .1371 .0521 P-value Median abs Error .0001 0 .0026 .0026 P-value Error < 1% 15.79% 27.63% 43.86% 50% P-value Error < 10% 24.21% 35.53% 66.67% 77.19% Significant Level Correctness 25.26% 31.58% 58.77% 70.18% Significant Level Error == 1 2.11% 3.95% 8.77% 9.65% Significant Level Error == 2 0.53% 0 3.51% 2.63% Significant Level Error == 3 1.05% 0.66% 7.02% 1.75% 

Partial Replication based on Task Type 

OLS, Panel OLS 24.35% 23.91% 42.03% 42.03% Propensity Score Regression 3.33% 16.67% 72.22% 77.78% Instrument Variable (IV) 0 25% 20.83% 12.5% Differences in Differences (DID) 0 25% 11.11% 33.33% Regression Discontinuity Designs (RDD) 8% 15% 0 13.33% Data Processing 20% 25% 49.28% 47.83% Covariance Adjustment 19.31% 25% 37.93% 37.93% Fixed Effects 12.5% 16% 27.78% 27.78% Number of Tasks 225 180 135 135 

Table III . Paper Testset Performance with the three control groups. The case study is drawn from Almond et al. (2005) with the theme of estimating the effect of maternal smoking during pregnancy on infant weights applying propensity score-related approaches. The first component is derived from the doctoral-level econometrics coursework materials and employs a propensity score-based regression adjustment method to conduct the analysis. This method was first introduced in Rosenbaum and Rubin (1983) and discussed by economists since Card and Sullivan (1988). With its advantages in maintaining sample completeness and supporting flexibility in non-linear & interaction effects, as well as its model simplicity, this method is commonly used as the first-step analysis among studies with propensity score-based methods. The question prompt is as follows: Please use the propensity score regression method to compute the effect of 

tobacco on dbrwt . You also need to control the following control variables: rec-type, csex, dmar, pldel3, pre4000, preterm, alcohol, dmage, demduc, dlivord, monpre, nprevist, dplural, birattnd, cntocpop, ormoth, mrace3, adequacy, delmeth5 .15 Besides, you need to consider the following requirements: birattnd, cntocpop, ormoth, mrace3, adequacy, delmeth5 are multi-class categorical variables. Trim the samples with the highest 10% score and the lowest 10% score 

You could load the corresponding data from /home/data/ps 1 24 S cleaned.dta .At the end of the program, please print the coefficient, standard error and p-value of the effect in a json format like {“coef f icient ” : 1 , “standard error ” : 2 , “p-value ” : 0 .5},and output the json string as a .json file. The empirical research process begins with data pre-processing and matching, including data file merging, variable selection (dependent, independent, and control variables), and handling missing values. The analysis requires: 1. Constructing propensity scores using logistic or probit models (given the binary treatment variable tobacco ). 2. Trimming samples to exclude extreme propensity scores (e.g., below 0 .1 or above 0 .9) to ensure sufficient overlap between treatment and control groups. 3. Running OLS regression with dbrwt as the dependent variable and both tobacco and the propensity score as independent variables. Using the provided dataset, the standard solution yields an ATE of −207 .7272 with standard error 5.508. One may also add the covariates into the second-stage OLS regression, which would produce an alternative ATE of −212 .9892 with standard error 5 .071. In the following, we compare the Econometrics AI Agent with the three control groups in terms of problem-solving procedures, highlighting common LLM tool limitations and demonstrating how the Econometrics AI Agent addresses them. All code generation and execution records are available online and can be accessed via https://github.com/HKU-Business-AI-Center/Econometrics-Agent. 

A. Python Code Generation: LLM and AI Agents 

Direct code generation by LLMs appears to be a straightforward solution given the clear re-quirements and simple knowledge base. However, LLM hallucinations frequently disrupt code gen-eration, where even minor errors can cause program termination without any meaningful results. The GPT-generated Python script demonstrates this vulnerability. As propensity score regression adjustment lacks built-in Python implementation, LLMs must generate complete data processing and regression procedures. Without self-correction capabilities, hallucinations occur in two areas, causing coding errors and execution failure: 

• Syntax Error: After the “pd.get dummies” operation, all variables affected are transformed into new columns with new labels (Figure B.1 in Appendix B). LLMs fail to detect this label change, during code generation, causing execution termination. 

• Logic Error: During categorical variable preparation, GPT incorrectly applies dummy variable transformation to all covariates, including continuous variables, rather than only categorical 16 predictors (Figure B.2 in Appendix B). This deviation violates problem requirements, creating an oversized right-hand-side dataset (exceeding 112313 × 112313) and triggering errors. Unlike direct LLM code generation, the general-purpose AI agent avoids coding errors through its reflection capabilities. However, Figure B.3 in Appendix B reveals a behavioral bias of the agent. Since logistic regression, the first step of this analysis, is common in machine learning, the agent follows machine learning conventions by splitting data into training and test sets. This approach conflicts with standard econometric practice, which emphasizes empirical explanation rather than prediction, making such splitting unnecessary. The resulting estimates deviate significantly from the correct answer, yielding an ATE of −103 .7577 with standard error 15 .8834. Far from coincidental, this behavioral bias reflects a systemic issue stemming from the substan-tially greater accessibility of machine learning materials compared to econometric code resources. The Econometrics AI Agent addresses this bias through two mechanisms: detailed internal prompts that enforce econometric standards, and a specialized tool library that ensures adherence to econo-metric conventions. 

B. Stata Code Generated by LLM 

Since Stata provides numerous built-in data pre-processing methods and econometric algo-rithms, LLMs generate Stata code more effectively than Python code for econometric analysis. Moreover, Stata’s specialized focus on econometrics, rather than machine learning, means its scripts in training samples naturally guide LLMs toward standard econometric approaches. However, Stata’s function library lacks a built-in function specifically for propensity score regression adjust-ment. After obtaining propensity scores, the optimal approach is to directly apply OLS for final estimation. Instead, as Figure B.4 in Appendix B shows, the hallucination issue arises, leading the LLM to mistakenly select propensity score matching for the second-step estimation. Although the results closely match the standard answer (ATE: −218 .9029, standard error: 7.5627), this methodological deviation render these estimates unreliable. The knowledge mismatch error is another aspect of the hallucination issue that requires careful attention. For tasks related to propensity score, although OLS regression adjustment is simpler, LLMs tend to select the more popular and well-documented propensity score matching method, following their tendency to generate the most probable tokens. In contrast, the Econometrics AI Agent has two advantages that prevent this error: First, its tool library supports user-customized functions tailored to specific needs, including less common methods. For this task specifically, the Agent is equipped with both propensity score regression adjustment functionality and various other propensity score-based econometric methods. Second, the selection of econometric algorithms (and their corresponding tool functions) does not rely on LLM generation capabilities. Instead, the tool recommendation procedure introduced in Section III first identifies the tool that best matches the task requirements. Only after that does LLM generate corresponding codes to correctly apply the tool and finish the task. 17 C. Econometrics AI Agent Operation Record 

The Econometrics AI Agent decomposes this task into three steps. The first two steps—“Load and preprocess the dataset from a specified file path” and “Perform exploratory data analysis on the dataset”—follow standard empirical econometric paradigms under internal prompt instructions. These steps complete essential data preparation, including categorical variable one-hot encoding and data cleaning. Furthermore, as Figure B.5 in Appendix B shows, the Econometrics AI Agent’s precise workflow requirements prevent the coding errors observed in control groups. For the final step, “Apply propensity score regression, controlling for specified variables and trimming samples,” the Econometrics AI Agent utilizes built-in tool functions to construct propen-sity scores and conduct regression adjustment analysis, as shown in Figure B.6 in Appendix B. After tool selection, the LLM focuses solely on preparing correct inputs to meet task requirements. This approach significantly reduces both the knowledge mismatch error from LLM hallucination and the behavioral bias through standardized tool functions. The final estimates (ATE: −207 .8559, standard error: 5 .4845) closely match the standard answer, validating the results. 

D. More Illustration Towards Knowledge Hallucination Issue 

Beyond the discussions in Almond et al. (2005), subsequent studies have further explored propensity score methods for treatment effect identification. Take Cattaneo (2010) as an exam-ple. Based on their analytical frameworks, we formulate another propensity score matching task, which embeds the more commonly-used propensity score-based methodology, with the following instruction prompt: Please use the propensity score matching method to compute the ATE of to-bacco on dbrwt . You also need to control the following control variables: mmarried, mage, mage2, fbaby, medu .Besides, you need to consider the following requirements: need to construct mage2 by taking the squared value of mage; use one-to-one matching; mb-smoke, mmarried, fbaby are dummy variables, and other variables are nu-merical variables 

You could load the corresponding data from /home/data/cattaneo.dta .At the end of the program, please print the estimated ATE in a json format like 

{“AT E ” : 0 .2}, and output the json string as a .json file. The manual solution procedure follows similar initial steps as the propensity score regression adjustment method. For ATE estimation, a nearest-neighbor matching method is applied to both treatment and control groups using estimated propensity scores. The final estimate is derived from the mean difference between groups across all included entities. Under the specified settings, this procedure yields an ATE estimate of −210 .9683. Since propensity score matching is a built-in Stata function, GPT-generated Stata code provides succinct solutions. However, for Python implementations, where no popular packages exist for 18 this method, the generated code must implement the method step-by-step. Here, the knowledge hallucination issue emerges consistently in our tests: as Figure B.7 in Appendix B shows, GPT models claim to calculate ATE while actually producing ATET (Average Treatment Effect on the Treated) estimates. This error stems from LLMs’ domain knowledge limitations. While general-purpose AI agents can use internal prompts to guide LLM behavior, such guidance is not sufficient and cannot ensure comprehensive knowledge of every domain-specific detail. This example therefore provides direct evidence for the advantage of the Econometrics AI Agent’s tool library design. Figure B.8 in Appendix B demonstrates how the core LLM, supported by a well-established knowledge and tool library, avoids knowledge hallucination under the Econo-metrics AI Agent framework. Rather than solely relying on LLMs’ content generation ability to perform domain knowledge-driven tasks—which are often complicated, in-depth, and sometimes uncommon and ambiguous—the tool library greatly simplifies LLMs’ generation and decision pro-cesses while guaranteeing domain knowledge capability. Beyond this straightforward case example and simple methodology, the tool library’s robustness, flexibility, and extensibility ensure the elim-ination of knowledge hallucination across more complex tasks and algorithms. 

# VI. Conclusions 

The AI era has brought significant productivity gains across various domains, yet challenges persist in fields requiring deep domain expertise. We introduce the Econometrics AI Agent, a LLM-driven specialized system that automates econometric analysis. Through a carefully customized agent structure, it executes complete econometric analyses while dynamically adapting to user feedback. The agent incorporates a simple yet robust zero-shot learning framework that enables continuous functionality expansion, both within econometrics and across other knowledge domains. We demonstrate the agent’s superior performance through empirical testing on coursework assign-ments and economics papers, complemented by in-depth case study comparisons against standard LLMs and general-purpose AI agents. The Econometrics AI Agent’s excellent performance demonstrates its significant potential for fu-ture applications. Beyond reducing learning barriers for econometrics students, it provides academic researchers and industry practitioners with efficient tools for research tasks. As leading academic journals increasingly require original data and replicable procedures, manual paper proofreading has become time-consuming and challenging. The Econometrics AI Agent can serve as an AI-driven digital referee for empirical research papers, significantly boosting proofreading efficiency (Mueller-Langer et al., 2019) while ensuring content quality and validity. Our work’s extensibility manifests in two key dimensions. First, the Econometrics AI Agent’s capabilities can be expanded by incorporating additional tool packages. For instance, addressing growing concerns about p-hacking in empirical research in business, economics, and social sciences, we developed a tool package using inverse optimization to analyze potential decision procedures regarding empirical test settings within given optimization spaces and datasets. This cost-effective 19 addition helps detect potential p-hacking risks in empirical research, offering an efficient alternative to manual review. Second, our zero-shot learning framework can extend to other knowledge-intensive domains. Through targeted instruction prompt refinement and domain-specific tool package development, this one-off setup enables new AI agents to deliver consistent, high-quality performance in their respective domains. This extensibility opens possibilities for future applications in areas such as quantitative investing and macroeconomics. 

# References 

Abraham, J., Olbert, M., & Vasvari, F. (2024). ESG Disclosures in the Private Equity Industry. 

Journal of Accounting Research , 62 (5), 1611–1660. Ahrens, M., Erdemlioglu, D., McMahon, M., Neely, C. J., & Yang, X. (2025). Mind your language: Market responses to central bank speeches. Journal of Econometrics , 249 , 105921. Almond, D., Chay, K., & Lee, D. (2005). The costs of low birth weight. The Quarterly Journal of Economics , 120 (3), 1031–1083. Anderson, M. (2008). Safety for whom? The effects of light trucks on traffic fatalities. Journal of Health Economics , 27 (4), 973–989. Armstrong, D. M., Glaeser, S., & Hoopes, J. L. (2024). Measuring firm exposure to government agencies. Journal of Accounting and Economics , 101703. Balsmeier, B., Fleming, L., Stiebale, J., & Veihl, M. (2024). The unintended impact of R&D tax credits on innovative search. The Review of Economics and Statistics , forthcoming. Brynjolfsson, E., Li, D., & Raymond, L. (2025). Generative AI at work. The Quarterly Journal of Economics , 140 (2), 889–942. Bursztyn, L., Rao, A., Roth, C., & Yanagizawa-Drott, D. (2022). Opinions as facts. The Review of Economic Studies , 90 , 1832–1864. Card, D., & Sullivan, D. (1988). Measuring the effect of subsidized training programs on movements in and out of employment. Econometrica , 56 (3), 497–530. Cattaneo, M. (2010). Efficient semiparametric estimation of multi-valued treatment effects under ignorability. Journal of Econometrics , 155 (2), 138–154. Chakraborty, I., Chiong, K., Dover, H., & Sudhir, K. (2025). Can AI and AI-hybrids detect per-suasion skills? Salesforce hiring with conversational video interviews. Marketing Science ,

44 (1), 30–53. Chen, Y., Kirshner, S. N., Ovchinnikov, A., Andiappan, M., & Jenkin, T. (2025). A manager and an AI walk into a bar: Does ChatGPT make biased decisions like we do? Manufacturing & Service Operations Management , 27 (2), 354–368. 20 Curti, F., & Kazinnik, S. (2023). Let’s face it: Quantifying the impact of nonverbal communication in FOMC press conferences. Journal of Monetary Economics , 139 , 110–126. Dell’Acqua, F., McFowland III, E., Mollick, E. R., Lifshitz-Assaf, H., Kellogg, K., Rajendran, S., Krayer, L., Candelon, F., & Lakhani, K. R. (2023). Navigating the jagged technological frontier: Field experimental evidence of the effects of AI on knowledge worker productivity and quality. https://ssrn.com/abstract=4573321 Doshi, A. R., & Hauser, O. P. (2024). Generative AI enhances individual creativity but reduces the collective diversity of novel content. Science Advances , 10 (28), eadn5290. Gmyrek, P., Lutz, C., & Newlands, G. (2024). A technological construction of society: Comparing GPT-4 and human respondents for occupational evaluation in the UK. British Journal of Industrial Relations , 63 , 180–208. Goli, A., & Singh, A. (2024). Frontiers: Can large language models capture human preferences? 

Marketing Science , 43 (4), 709–722. Gorodnichenko, Y., Pham, T., & Talavera, O. (2025). Central bank communication on social media: What, to whom, and how? Journal of Econometrics , 249 , 105869. Graeber, T., Roth, C., & Zimmermann, F. (2024). Stories, statistics, and memory. The Quarterly Journal of Economics , 139 (4), 2181–2225. Han, S. (2025). Mining causality: AI-assisted search for instrumental variables. https://arxiv.org/ abs/2409.14202 He, J., Rungta, M., Koleczek, D., Sekhon, A., Wang, F. X., & Hasan, S. (2024). Does prompt formatting have any impact on LLM performance? https://arxiv.org/abs/2411.10541 Hong, S., Lin, Y., Liu, B., Liu, B., Wu, B., Zhang, C., Wei, C., Li, D., Chen, J., Zhang, J., Wang, J., Zhang, L., Zhang, L., Yang, M., Zhuge, M., Guo, T., Zhou, T., Tao, W., Tang, X., . . . Wu, C. (2024). Data Interpreter: An LLM Agent For Data Science. https://arxiv.org/abs/ 2402.18679 Hong, S., Zhuge, M., Chen, J., Zheng, X., Cheng, Y., Wang, J., Zhang, C., Wang, Z., Yau, S. K. S., Lin, Z., Zhou, L., Ran, C., Xiao, L., Wu, C., & Schmidhuber, J. (2024). MetaGPT: Meta programming for a multi-agent collaborative framework. The Twelfth International Confer-ence on Learning Representations . https://openreview.net/forum?id=VtmBAGCN7o Hui, X., Reshef, O., & Zhou, L. (2024). The short-term effects of generative artificial intelligence on employment: Evidence from an online labor market. Organization Science , 35 (6), 1977– 1989. Korinek, A. (2023). Generative AI for economic research: Use cases and implications for economists. 

Journal of Economic Literature , 61 (4), 1281–1317. Lampert, C. H., Nickisch, H., & Harmeling, S. (2009). Learning to detect unseen object classes by between-class attribute transfer. IEEE Conference on Computer Vision and Pattern Recognition , 951–958. 21 Lampert, C. H., Nickisch, H., & Harmeling, S. (2014). Attribute-based classification for zero-shot visual object categorization. IEEE Transactions on Pattern Analysis and Machine Intelli-gence , 36 (3), 453–465. Larochelle, H., Erhan, D., & Bengio, Y. (2008). Zero-data learning of new tasks. Proceedings of the 23rd National Conference on Artificial Intelligence , 646–651. Leib, M., K¨ obis, N., Rilke, R. M., Hagens, M., & Irlenbusch, B. (2023). Corrupted by algorithms? How AI-generated and human-written advice shape (dis)honesty. The Economic Journal ,

134 (658), 766–784. Li, P., Castelo, N., Katona, Z., & Sarvary, M. (2024). Frontiers: Determining the validity of large language models for automated perceptual analysis. Marketing Science , 43 (2), 254–266. Ling, C., Zhao, X., Lu, J., Deng, C., Zheng, C., Wang, J., Chowdhury, T., Li, Y., Cui, H., Zhang, X., Zhao, T., Panalkar, A., Mehta, D., Pasquali, S., Cheng, W., Wang, H., Liu, Y., Chen, Z., Chen, H., . . . Zhao, L. (2024). Domain specialization as the key to make large language models disruptive: A comprehensive survey. https://arxiv.org/abs/2305.18703 Liu, H., Yin, H., Luo, Z., & Wang, X. (2025). Integrating chemistry knowledge in large language models via prompt engineering. Synthetic and Systems Biotechnology , 10 (1), 23–38. Ludwig, J., Mullainathan, S., & Rambachan, A. (2025). Large language models: An applied econo-metric framework. https://arxiv.org/abs/2412.07031 Manning, B. S., Zhu, K., & Horton, J. J. (2024). Automated social science: Language models as scientist and subjects. https://arxiv.org/abs/2404.11794 Meltzer, J. P. (2024). The Impact of Foundational AI on International Trade, Services and Supply Chains in Asia. Asian Economic Policy Review , 19 (1), 129–147. Mueller-Langer, F., Fecher, B., Harhoff, D., & Wagner, G. G. (2019). Replication studies in eco-nomics—How many and which papers are chosen for replication, and why? Research Policy ,

48 (1), 62–83. Niu, Y., Wu, J., Jiang, S., & Jiang, Z. (2025). The bullwhip effect in servitized manufacturers. 

Management Science , 71 (1), 1–20. Noailly, J., Nowzohour, L., van den Heuvel, M., & Pla, I. (2024). Heard the news? Environmental policy and clean investments. Journal of Public Economics , 238 , 105190. Noy, S., & Zhang, W. (2023). Experimental evidence on the productivity effects of generative artificial intelligence. Science , 381 (6654), 187–192. OpenAI. (2023). GPT-4 technical report. https://arxiv.org/abs/2303.08774 Rosenbaum, P., & Rubin, D. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika , 70 (1), 41–55. Singhal, K., Tu, T., Gottweis, J., Sayres, R., Wulczyn, E., Amin, M., Hou, L., Clark, K., Pfohl, S. R., Cole-Lewis, H., Neal, D., Rashid, Q. M., Schaekermann, M., Wang, A., Dash, D., Chen, J. H., Shah, N. H., Lachgar, S., Mansfield, P. A., . . . Natarajan, V. (2025). Toward expert-22 level medical question answering with large language models. Nature Medicine , 31 (3), 943– 950. Stroube, B. K., & Waguespack, D. M. (2024). Status and consensus: Heterogeneity in audience evaluations of female- versus male-lead films. Strategic Management Journal , 45 (5), 994– 1024. Wang, A., Pruksachatkun, Y., Nangia, N., Singh, A., Michael, J., Hill, F., Levy, O., & Bowman, S. (2019). SuperGLUE: A stickier benchmark for general-purpose language understanding systems. Advances in Neural Information Processing Systems 32 , 3266–3280. Wu, S., Irsoy, O., Lu, S., Dabravolski, V., Dredze, M., Gehrmann, S., Kambadur, P., Rosenberg, D., & Mann, G. (2023). BloombergGPT: A large language model for finance. https://arxiv. org/abs/2303.17564 Xia, Y., Kim, J., Chen, Y., Ye, H., Kundu, S., Hao, C. C., & Talati, N. (2024). Understanding the performance and estimating the cost of LLM fine-tuning. 2024 IEEE International Symposium on Workload Characterization (IISWC) , 210–223. Xu, Z., Shi, Z., & Liang, Y. (2024). Do large language models have compositional ability? An investi-gation into limitations and scalability. ICLR 2024 Workshop on Mathematical and Empirical Understanding of Foundation Models . https://openreview.net/forum?id=4XPeF0SbJs Yao, J., Xu, W., Lian, J., Wang, X., Yi, X., & Xie, X. (2023). Knowledge plugins: Enhancing large language models for domain-specific recommendations. https://arxiv.org/abs/2311.10779 Yoganarasimhan, H., & Iakovetskaia, I. (2024). From feeds to inboxes: A comparative study of polarization in Facebook and email news sharing. Management Science , 70 (9), 6461–6472. 23 Appendix A. Tool Design, Tool Selection and Internal Prompt 

Figure A.1. An Example of Econometrics Tool and Internal Prompt 

Figure A.2. An Example of Econometrics Tool Selection Procedure 

24 Appendix B. Case Study Response Examples 

Figure B.1. Case Study — GPT(py) Hallucination Problem 1 

Figure B.2. Case Study — GPT(py) Hallucination Problem 2 

25 Figure B.3. Case Study — General AI Agent Hallucination Problem 

Figure B.4. Case Study — GPT(stata) Hallucination Problem 

26 Figure B.5. Case Study — Econometrics AI Agent Operation Record 1 

Figure B.6. Case Study — Econometrics AI Agent Operation Record 2 

27 Figure B.7. Case Study — Knowledge Hallucination Example 

Figure B.8. Case Study — Econometrics AI Agent Knowledge Hallucination Solution 

28
